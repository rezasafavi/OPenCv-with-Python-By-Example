{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf59e399",
   "metadata": {},
   "source": [
    "# Reading, displaying, and saving images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b77de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a50a468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "cv2.imshow(\"input image\",img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee190cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img = cv2.imread(\"BingWallpaper (1).jpg\" , cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Grayscale\",gray_img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af90c2e",
   "metadata": {},
   "source": [
    "# Converting between color spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13296cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Grayscale image',gray_img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0582b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "yuv_img = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "cv2.imshow('Grayscale image',yuv_img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6e41c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "yuv_img = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "cv2.imshow('Y channel ',yuv_img[:,:,0])\n",
    "cv2.imshow('U channel ',yuv_img[:,:,1])\n",
    "cv2.imshow('V channel ',yuv_img[:,:,2])\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed76f22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow('Grayscale image',hsv_img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ead2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow('H channel ',hsv_img[:,:,0])\n",
    "cv2.imshow('S channel ',hsv_img[:,:,1])\n",
    "cv2.imshow('V channel ',hsv_img[:,:,2])\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c6cb3d",
   "metadata": {},
   "source": [
    "# Image rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc169d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img =cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "num_rows , num_cols = img.shape[:2]\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((num_cols/2,num_rows/2),30,1)\n",
    "img_rotation = cv2.warpAffine(img,rotation_matrix,(num_cols,num_rows))\n",
    "cv2.imshow(\"Rotation\",img_rotation)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281428d3",
   "metadata": {},
   "source": [
    "# Image translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e4bd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function waitKey>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img =cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "num_rows , num_cols = img.shape[:2]\n",
    "\n",
    "translation_matrix = np.float32([[1,0,70],[0,1,110]])\n",
    "img_translation = cv2.warpAffine(img,translation_matrix,(num_cols,num_rows))\n",
    "\n",
    "cv2.imshow(\"Translation\" , img_translation)\n",
    "cv2.waitKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e640362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function waitKey>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img =cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "num_rows , num_cols = img.shape[:2]\n",
    "\n",
    "translation_matrix = np.float32([[1,0,70],[0,1,110]])\n",
    "img_translation = cv2.warpAffine(img,translation_matrix,(num_cols + 70,num_rows + 110))\n",
    "\n",
    "translation_matrix = np.float32([[1,0,-30],[0,1,-50]])\n",
    "img_translation = cv2.warpAffine(img,translation_matrix,(num_cols + 70 + 30,num_rows + 110 + 50))\n",
    "\n",
    "cv2.imshow(\"Translation\" , img_translation)\n",
    "cv2.waitKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9fd5d9",
   "metadata": {},
   "source": [
    "# Image scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabc9369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img =cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "img_scaled = cv2.resize(img,None,fx=1.2,fy=1.2,interpolation = cv2.INTER_LINEAR)\n",
    "cv2.imshow('Scaling - Linear Interpolation' ,img_scaled)\n",
    "img_scaled = cv2.resize(img,None,fx=1.2,fy=1.2,interpolation =cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling - Cubic Interploatayion', img_scaled)\n",
    "img_scaled = cv2.resize(img,None,fx=1.2,fy=1.2,interpolation =cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling - Area Interpolation', img_scaled)\n",
    "cv2.imshow('Scaling - Skewed Size', img_scaled)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a125d5b4",
   "metadata": {},
   "source": [
    "# Image warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"BingWallpaper (1).jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "rows , cols = img.shape\n",
    "#################################################\n",
    "# Vertical Wave\n",
    "\n",
    "img_output = np.zeros(img.shape,dtype = img.dtype)\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        offset_x = int(25.0*math.sin(2*3.14*i/180))\n",
    "        offset_y = 0\n",
    "        if j+offset_x < rows:\n",
    "            img_output[i,j] = img[i,(j+offset_x)%cols]\n",
    "        else: \n",
    "            img_output[i,j] = 0\n",
    "cv2.imshow('Innput' , img)\n",
    "cv2.imshow('Vertical Wave' , img_output)\n",
    "\n",
    "\n",
    "################################################\n",
    "# Horzintal Wave\n",
    "\n",
    "img_output = np.zeros(img.shape,dtype = img.dtype)\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        offset_x=0\n",
    "        offset_y=int(16.0 * math.sin(2*3.14*j/150))\n",
    "        if i+offset_y <rows:\n",
    "            img_output[i,j] = img[(i+offset_y)%rows,j]\n",
    "        else:\n",
    "            img_output[i,j] = 0\n",
    "cv2.imshow('Horzintal Wave',img_output)\n",
    "\n",
    "################################################\n",
    "# Both horzintal and vertical\n",
    "\n",
    "img_output = np.zeros(img.shape,dtype=img.dtype)\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        offset_x = int(20.0*math.sin(2*3.14*i/150))\n",
    "        offset_y = int(20.0*math.cos(2*3.14*j/150))\n",
    "        if i-offset_y < rows and j+offset_x < cols:\n",
    "            img_output[i,j] = img[(i+offset_y)%rows , (j+offset_x)%cols]\n",
    "        else:\n",
    "            img_output[i,j] = 0\n",
    "cv2.imshow('Multidirectional Wave'  ,img_output)\n",
    "\n",
    "##################################################\n",
    "# Concave effect \n",
    "\n",
    "img_output = np.zeros(img.shape,dtype = img.dtype)\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        offset_x = int(128.0*math.sin(2*3.14*i/(2*cols)))\n",
    "        offset_y = 0\n",
    "        if j+offset_x < cols:\n",
    "            img_output[i,j] = img[i,(j+offset_x)%cols]\n",
    "        else: \n",
    "            img_output[i,j] = 0\n",
    "            \n",
    "cv2.imshow('Concave' , img_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e972390",
   "metadata": {},
   "source": [
    "# Detecting Edges and Applying Image Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c59d2",
   "metadata": {},
   "source": [
    "# Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1bd0cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "kernel_identity = np.array([[0,0,0], [0,1,0], [0,0,0]])\n",
    "kernel_3x3 = np.ones((3,3), np.float32) / 9.0\n",
    "kernel_5x5 = np.ones((5,5), np.float32) / 25.0\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "output = cv2.filter2D(img, -1, kernel_identity)\n",
    "cv2.imshow('Identity filter', output)\n",
    "\n",
    "output = cv2.filter2D(img, -1, kernel_3x3)\n",
    "cv2.imshow('3x3 filter', output)\n",
    "\n",
    "output = cv2.filter2D(img, -1, kernel_5x5)\n",
    "cv2.imshow('5x5 filter', output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed60d0",
   "metadata": {},
   "source": [
    "# Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50a4a094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"BingWallpaper (1).jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "rows, cols = img.shape\n",
    "\n",
    "sobel_horizontal = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobel_vertical = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Sobel horizontal', sobel_horizontal)\n",
    "cv2.imshow('Sobel vertical', sobel_vertical)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b55f3d6",
   "metadata": {},
   "source": [
    "# Motion blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c976ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "cv2.imshow('Original', img)\n",
    "size = 15\n",
    "\n",
    "# generating the kernel\n",
    "kernel_motion_blur = np.zeros((size, size))\n",
    "kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "kernel_motion_blur = kernel_motion_blur / size\n",
    "\n",
    "# applying the kernel to the input image\n",
    "output = cv2.filter2D(img, -1, kernel_motion_blur)\n",
    "cv2.imshow('Motion Blur', output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87c99b9",
   "metadata": {},
   "source": [
    "# Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74169244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "# generating the kernels\n",
    "kernel_sharpen_1 = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "kernel_sharpen_2 = np.array([[1,1,1], [1,-7,1], [1,1,1]])\n",
    "kernel_sharpen_3 = np.array([[-1,-1,-1,-1,-1],\n",
    "                             [-1,2,2,2,-1],\n",
    "                             [-1,2,8,2,-1],\n",
    "                             [-1,2,2,2,-1],\n",
    "                             [-1,-1,-1,-1,-1]]) / 8.0\n",
    "\n",
    "# applying different kernels to the input image\n",
    "output_1 = cv2.filter2D(img, -1, kernel_sharpen_1)\n",
    "output_2 = cv2.filter2D(img, -1, kernel_sharpen_2)\n",
    "output_3 = cv2.filter2D(img, -1, kernel_sharpen_3)\n",
    "\n",
    "cv2.imshow('Sharpening', output_1)\n",
    "cv2.imshow('Excessive Sharpening', output_2)\n",
    "cv2.imshow('Edge Enhancement', output_3)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f500e6f8",
   "metadata": {},
   "source": [
    "# Embossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da66dea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img_emboss_input = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "# generating the kernels\n",
    "\n",
    "kernel_emboss_1 = np.array([[0,-1,-1],\n",
    "                            [1,0,-1],\n",
    "                            [1,1,0]])\n",
    "kernel_emboss_2 = np.array([[-1,-1,0],\n",
    "                            [-1,0,1],\n",
    "                            [0,1,1]])\n",
    "kernel_emboss_3 = np.array([[1,0,0],\n",
    "                            [0,0,0],\n",
    "                            [0,0,-1]])\n",
    "# converting the image to grayscale\n",
    "gray_img = cv2.cvtColor(img_emboss_input,cv2.COLOR_BGR2GRAY)\n",
    "# applying the kernels to the grayscale image and adding the offset\n",
    "output_1 = cv2.filter2D(gray_img, -1, kernel_emboss_1) + 128\n",
    "output_2 = cv2.filter2D(gray_img, -1, kernel_emboss_2) + 128\n",
    "output_3 = cv2.filter2D(gray_img, -1, kernel_emboss_3) + 128\n",
    "\n",
    "cv2.imshow('Input', img_emboss_input)\n",
    "cv2.imshow('Embossing - South West', output_1)\n",
    "cv2.imshow('Embossing - South East', output_2)\n",
    "cv2.imshow('Embossing - North West', output_3)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba950c19",
   "metadata": {},
   "source": [
    "# Erosion and dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f1d2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"BingWallpaper (1).jpg\", 0)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "img_erosion = cv2.erode(img, kernel, iterations=1)\n",
    "img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "cv2.imshow('Input', img)\n",
    "cv2.imshow('Erosion', img_erosion)\n",
    "cv2.imshow('Dilation', img_dilation)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0f317",
   "metadata": {},
   "source": [
    "# Creating a vignette filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf8446b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "# generating vignette mask using Gaussian kernels\n",
    "kernel_x = cv2.getGaussianKernel(cols,200)\n",
    "kernel_y = cv2.getGaussianKernel(rows,200)\n",
    "kernel = kernel_y * kernel_x.T\n",
    "mask = 255 * kernel / np.linalg.norm(kernel)\n",
    "output = np.copy(img)\n",
    "\n",
    "# applying the mask to each channel in the input image\n",
    "for i in range(3):\n",
    "    output[:,:,i] = output[:,:,i] * mask\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Vignette', output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55ba8d",
   "metadata": {},
   "source": [
    "# Enhancing the contrast in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4af13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"BingWallpaper (1).jpg\", 0)\n",
    "\n",
    "# equalize the histogram of the input image\n",
    "histeq = cv2.equalizeHist(img)\n",
    "cv2.imshow('Input', img)\n",
    "cv2.imshow('Histogram equalized', histeq)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3969a3",
   "metadata": {},
   "source": [
    "# How do we handle color images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8adc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "# equalize the histogram of the Y channel\n",
    "img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "\n",
    "# convert the YUV image back to RGB format\n",
    "img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "cv2.imshow('Color input image', img)\n",
    "cv2.imshow('Histogram equalized', img_output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f8eeb",
   "metadata": {},
   "source": [
    "# Accessing the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81300de6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 5 (3254080328.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [2]\u001b[1;36m\u001b[0m\n\u001b[1;33m    raise IOError(\"Cannot open webcam\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'if' statement on line 5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "raise IOError(\"Cannot open webcam\")\n",
    "while True:\n",
    "ret, frame = cap.read()\n",
    "frame = cv2.resize(frame, None, fx=0.5, fy=0.5,\n",
    "interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('Input', frame)\n",
    "c = cv2.waitKey(1)\n",
    "if c == 27:\n",
    "break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a51ef43",
   "metadata": {},
   "source": [
    "# Keyboard inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e593a549",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 4) (612104546.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [4]\u001b[1;36m\u001b[0m\n\u001b[1;33m    parser = argparse.ArgumentParser(description=\"Change color space of the\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 4)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "def argument_parser():\n",
    "parser = argparse.ArgumentParser(description=\"Change color space of the\n",
    "\\\n",
    "                                 input video stream using keyboard controls. The control keys\n",
    "are:\\\n",
    "                                 Grayscale - 'g', YUV - 'y', HSV - 'h'\")\n",
    "    return parser\n",
    "if __name__=='__main__':\n",
    "    args = argument_parser().parse_args()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "cur_char = -1\n",
    "prev_char = -1\n",
    "\n",
    "\n",
    "while True:    \n",
    "    # Read the current frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "    # Resize the captured image\n",
    "    frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "    if c > -1 and c != prev_char:\n",
    "        cur_char = c\n",
    "    prev_char = c\n",
    "        \n",
    "    if cur_char == ord('g'):\n",
    "        output = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    elif cur_char == ord('y'):\n",
    "        output = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV)\n",
    "        \n",
    "    elif cur_char == ord('h'):\n",
    "        output = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    else:\n",
    "        output = frame\n",
    "        \n",
    "cv2.imshow('Webcam', output)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5144f",
   "metadata": {},
   "source": [
    "# Mouse inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c90ae",
   "metadata": {},
   "source": [
    "# import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_quadrant(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if x > width/2:\n",
    "            if y > height/2:\n",
    "                point_top_left = (int(width/2), int(height/2))\n",
    "                point_bottom_right = (width-1, height-1)\n",
    "            else:\n",
    "                point_top_left = (int(width/2), 0)\n",
    "                point_bottom_right = (width-1, int(height/2))\n",
    "        else:\n",
    "            if y > height/2:\n",
    "                point_top_left = (0, int(height/2))\n",
    "                point_bottom_right = (int(width/2), height-1)\n",
    "        else:\n",
    "                point_top_left = (0, 0)\n",
    "                point_bottom_right = (int(width/2), int(height/2))\n",
    "                \n",
    "                \n",
    "        cv2.rectangle(img, (0,0), (width-1,height-1), (255,255,255), -1)\n",
    "        cv2.rectangle(img, point_top_left, point_bottom_right, (0,100,0),-1)\n",
    "            \n",
    "    if __name__=='__main__':\n",
    "        width, height = 640, 480\n",
    "        img = 255 * np.ones((height, width, 3), dtype=np.uint8)\n",
    "        cv2.namedWindow('Input window')\n",
    "        cv2.setMouseCallback('Input window', detect_quadrant)\n",
    "        \n",
    "    while True:\n",
    "        cv2.imshow('Input window', img)\n",
    "        c = cv2.waitKey(10)\n",
    "        if c == 27:\n",
    "            break\n",
    "            \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de97be4",
   "metadata": {},
   "source": [
    "# Interacting with a live video stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065e625d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (869460535.py, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [3]\u001b[1;36m\u001b[0m\n\u001b[1;33m    while True:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_rectangle(event, x, y, flags, params):\n",
    "    global x_init, y_init, drawing, top_left_pt, bottom_right_pt\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        x_init, y_init = x, y\n",
    "        \n",
    "        \n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            top_left_pt = (min(x_init, x), min(y_init, y))\n",
    "            bottom_right_pt = (max(x_init, x), max(y_init, y))\n",
    "            img[y_init:y, x_init:x] = 255 - img[y_init:y, x_init:x]\n",
    "            \n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        top_left_pt = (min(x_init, x), min(y_init, y))\n",
    "        bottom_right_pt = (max(x_init, x), max(y_init, y))\n",
    "        img[y_init:y, x_init:x] = 255 - img[y_init:y, x_init:x]\n",
    "            \n",
    "    if __name__=='__main__':\n",
    "        drawing = False\n",
    "        top_left_pt, bottom_right_pt = (-1,-1), (-1,-1)\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "    # Check if the webcam is opened correctly\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "        \n",
    "cv2.namedWindow('Webcam')\n",
    "cv2.setMouseCallback('Webcam', draw_rectangle)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        img = cv2.resize(frame, None, fx=0.5, fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "        (x0,y0), (x1,y1) = top_left_pt, bottom_right_pt\n",
    "        img[y0:y1, x0:x1] = 255 - img[y0:y1, x0:x1]\n",
    "        cv2.imshow('Webcam', img)        \n",
    "        c = cv2.waitKey(1)\n",
    "        if c == 27:\n",
    "            break\n",
    "            \n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa81cc",
   "metadata": {},
   "source": [
    "# Cartoonizing an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67fe33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cartoonize_image(img, ds_factor=4, sketch_mode=False):\n",
    "    # Convert image to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply median filter to the grayscale image\n",
    "    img_gray = cv2.medianBlur(img_gray, 7)\n",
    "    \n",
    "    # Detect edges in the image and threshold it\n",
    "    edges = cv2.Laplacian(img_gray, cv2.CV_8U, ksize=5)\n",
    "    ret, mask = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # 'mask' is the sketch of the image\n",
    "    if sketch_mode:\n",
    "        return cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "        \n",
    "    # Resize the image to a smaller size for faster computation\n",
    "    img_small = cv2.resize(img, None, fx=1.0/ds_factor, fy=1.0/ds_factor,interpolation=cv2.INTER_AREA)\n",
    "    num_repetitions = 10\n",
    "    sigma_color = 5\n",
    "    sigma_space = 7\n",
    "    size = 5\n",
    "    \n",
    "    # Apply bilateral filter the image multiple times\n",
    "    for i in range(num_repetitions):\n",
    "        img_small = cv2.bilateralFilter(img_small, size, sigma_color,sigma_space)\n",
    "    img_output = cv2.resize(img_small, None, fx=ds_factor, fy=ds_factor,interpolation=cv2.INTER_LINEAR)\n",
    "    dst = np.zeros(img_gray.shape)\n",
    "    \n",
    "    # Add the thick boundary lines to the image using 'AND' operator\n",
    "    dst = cv2.bitwise_and(img_output, img_output, mask=mask)\n",
    "    return dst\n",
    "\n",
    "if __name__=='__main__':\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    cur_char = -1\n",
    "    prev_char = -1\n",
    "\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame, None, fx=0.5, fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        c = cv2.waitKey(1)\n",
    "        if c == 27:\n",
    "        break\n",
    "        if c > -1 and c != prev_char:\n",
    "            cur_char = c\n",
    "        prev_char = c\n",
    "        \n",
    "        if cur_char == ord('s'):\n",
    "            cv2.imshow('Cartoonize', cartoonize_image(frame,sketch_mode=True))\n",
    "        elif cur_char == ord('c'):\n",
    "            cv2.imshow('Cartoonize', cartoonize_image(frame,sketch_mode=False))\n",
    "        else:\n",
    "            cv2.imshow('Cartoonize', frame)\n",
    "            \n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab739b2",
   "metadata": {},
   "source": [
    "# Deconstructing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f57d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"BingWallpaper (1).jpg\")\n",
    "output = cv2.medianBlur(img, 7)\n",
    "cv2.imshow('Input', img)\n",
    "cv2.imshow('Median filter', output)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922c03e",
   "metadata": {},
   "source": [
    "# Detecting and tracking faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eed6fa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 22 (3488455718.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [3]\u001b[1;36m\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'if' statement on line 22\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./cascade_files/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "scaling_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor,\n",
    "interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    face_rects = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in face_rects:\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "        \n",
    "    cv2.imshow('Face Detector', frame)\n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "    break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd7c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
